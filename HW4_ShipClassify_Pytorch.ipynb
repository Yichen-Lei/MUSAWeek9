{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm\n\nimport matplotlib.image as mpimg\nimport json\n\nfrom skimage.color import rgb2gray\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\n\n\nimport matplotlib.pyplot as plt\n\n\ndataFolder = \"/kaggle/input/ships-in-satellite-imagery/shipsnet/shipsnet/\"\n\n\nwith open('/kaggle/input//ships-in-satellite-imagery/shipsnet.json') as data_file:\n    data = json.load(data_file)\nlabelDf = pd.DataFrame(data)\n\n\nimgFiles = os.listdir(dataFolder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport time\nimport copy\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as func\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom torchvision.transforms import ToTensor,Resize\n\nfrom torchvision import models\n\nfrom torch.optim import lr_scheduler\n\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining the data augmentation steps\ntransform = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining the PyTorch Dataset for retrieving the ships data\nclass ShipDataset(torch.utils.data.Dataset):\n  def __init__(self, imgFiles, transform, index=None):\n    \n    \n    self.imgFiles = imgFiles\n    self.transform = transform\n\n    \n    \n  def __len__(self):\n    \n    return len(self.imgFiles)\n    \n  def __getitem__(self, index):\n    \n    filename = self.imgFiles[index]\n    \n    img =  Image.open(os.path.join(dataFolder, filename)).convert('RGB')\n    \n    \n    label = int(filename.split(\"_\")[0])\n    \n    \n    if self.transform is not None:\n        img = self.transform(img)\n        \n    img = img/255.0\n      \n#     label = torch.FloatTensor([label])\n\n    return img, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device='cuda'\n\n#Splitting data for train/validation\ntrainDataset = ShipDataset(imgFiles[:3500], transform)\ntestDataset = ShipDataset(imgFiles[3500:], transform)\n\n#Defining dataloaders\ntrainLoader = torch.utils.data.DataLoader(trainDataset, batch_size=30, \n                                          shuffle=True, num_workers=2)\n\n\ntestLoader = torch.utils.data.DataLoader(testDataset, batch_size=40, \n                                          shuffle=False, num_workers=2)\n\n\n#Define the loss functions\ncriteria = nn.CrossEntropyLoss()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_datasets = {'train':trainDataset, 'val':testDataset}\n\ndataloaders = {\"train\":trainLoader, \"val\":testLoader}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#Defining model architecture. Transfer Learning using Resnet34\nnet = models.resnet34(pretrained=True)\nnet.fc = nn.Linear(512,2)\n\n\nnet.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n#Defining Learning Rate scheduler\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def freezeLayers(net):\n    \n    ## Freeze all layers\n    for child in net.children():\n        for param in child.parameters():\n            param.requires_grad = False\n\n    ## Unfreezing the last FC layer        \n    for param in list(net.children())[-1].parameters():\n        param.requires_grad = True\n        \n    return net\n    \n    \ndef unfreezeLayers(net):\n    \n    ## Freeze all layers\n    for child in net.children():\n        for param in child.parameters():\n            param.requires_grad = True\n            \n    return net","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, epoch_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#Freezing the backbone and training\nnet = freezeLayers(net)\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), 1e-3)\n\ntrain_model(net,criterion, optimizer, exp_lr_scheduler, num_epochs = 6)\n\n#Training the whole network\nnet = unfreezeLayers(net)\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), 1e-4)\n\ntrain_model(net,criterion, optimizer, exp_lr_scheduler, num_epochs = 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def runTest(net, criterion, optimizer,exp_lr_scheduler ):\n    \n    net = freezeLayers(net)\n    model, acc = train_model(net,criterion, optimizer, exp_lr_scheduler, num_epochs = 6)\n    \n    net = unfreezeLayers(net)\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), 1e-4)\n\n    model, acc = train_model(net,criterion, optimizer, exp_lr_scheduler, num_epochs = 6)\n    \n    print(f\"Best Accuracy : {acc}\")\n    \n    return acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Performing 10-Fold Cross Validation\nimgFiles = np.array(imgFiles)\n\naccList = []\n\n\nfor i in tqdm(range(10)):\n    \n    test = list(range(i*setSize, (i+1)*setSize))\n    train = list(set(list(range(4000))).difference(set(test)))\n    \n    trainDataset = ShipDataset(imgFiles[train], transform)\n    testDataset = ShipDataset(imgFiles[test], transform)\n\n\n    trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size=30, \n                                              shuffle=True, num_workers=2)\n\n\n    testLoader = torch.utils.data.DataLoader(testDataset, batch_size=40, \n                                              shuffle=False, num_workers=2)\n    \n    \n    image_datasets = {'train':trainDataset, 'val':testDataset}\n    dataloaders = {\"train\":trainLoader, \"val\":testLoader}\n    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n    \n    \n    net = models.resnet34(pretrained=True)\n    net.fc = nn.Linear(512,2)\n    net.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), 1e-3)\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n    \n    \n    acc = runTest(net, criterion, optimizer,exp_lr_scheduler)\n    accList.append(acc)\n\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accList","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean([x.cpu().numpy() for x in accList])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}